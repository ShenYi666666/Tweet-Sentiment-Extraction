{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T12:18:46.151511Z",
     "start_time": "2020-04-18T12:18:44.803033Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T12:18:46.155672Z",
     "start_time": "2020-04-18T12:18:46.152671Z"
    }
   },
   "outputs": [],
   "source": [
    "def _improve_answer_span(doc_tokens, input_start, input_end, tokenizer, orig_answer_text):\n",
    "    \"\"\"Returns tokenized answer spans that better match the annotated answer.\"\"\"\n",
    "    tok_answer_text = \" \".join(tokenizer.tokenize(orig_answer_text))\n",
    "\n",
    "    for new_start in range(input_start, input_end + 1):\n",
    "        for new_end in range(input_end, new_start - 1, -1):\n",
    "            text_span = \" \".join(doc_tokens[new_start : (new_end + 1)])\n",
    "            if text_span == tok_answer_text:\n",
    "                return (new_start, new_end)\n",
    "\n",
    "    return (input_start, input_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_ids = pd.read_pickle('../input/localtest_ids.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T12:18:46.196823Z",
     "start_time": "2020-04-18T12:18:46.156490Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/tweet-sentiment-extraction/train.csv')\n",
    "train['type'] = 'normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27481, 5)\n",
      "(24001, 5)\n"
     ]
    }
   ],
   "source": [
    "# remove test\n",
    "print(train.shape)\n",
    "train = train[~train['textID'].isin(lt_ids['textID'].tolist())]\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo = pd.read_pickle('../input/roberta_pred.pkl')\n",
    "pseudo = pseudo[pseudo['score']>=1.2]\n",
    "pseudo['selected_text'] = pseudo['pred'].values\n",
    "pseudo['type'] = 'pseudo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo['text'] = pseudo['text'].apply(lambda x: ' '.join(x.lower().strip().split()))\n",
    "pseudo['selected_text'] = pseudo['selected_text'].apply(lambda x: ' '.join(x.lower().strip().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo.drop(pseudo[pseudo['selected_text']==''].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T12:18:46.241201Z",
     "start_time": "2020-04-18T12:18:46.197619Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('../../bert_models/roberta_base/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T12:18:46.247437Z",
     "start_time": "2020-04-18T12:18:46.242448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24001, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T12:18:46.255167Z",
     "start_time": "2020-04-18T12:18:46.248326Z"
    }
   },
   "outputs": [],
   "source": [
    "train.dropna(subset=['text','selected_text'], how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T12:18:46.258070Z",
     "start_time": "2020-04-18T12:18:46.255974Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T12:18:46.322384Z",
     "start_time": "2020-04-18T12:18:46.315985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28b57f3990</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "5  28b57f3990  http://www.dothebouncy.com/smf - some shameles...   \n",
       "\n",
       "                                       selected_text sentiment    type  \n",
       "0                I`d have responded, if I were going   neutral  normal  \n",
       "1                                           Sooo SAD  negative  normal  \n",
       "3                                     leave me alone  negative  normal  \n",
       "4                                      Sons of ****,  negative  normal  \n",
       "5  http://www.dothebouncy.com/smf - some shameles...   neutral  normal  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T12:18:46.810705Z",
     "start_time": "2020-04-18T12:18:46.746472Z"
    }
   },
   "outputs": [],
   "source": [
    "train['text'] = train['text'].apply(lambda x: ' '.join(x.lower().strip().split()))\n",
    "train['selected_text'] = train['selected_text'].apply(lambda x: ' '.join(x.lower().strip().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T12:18:50.940931Z",
     "start_time": "2020-04-18T12:18:50.934743Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean(x):\n",
    "    sp_x = x.split()\n",
    "    if sp_x[0] in [',','.','!','?',':',';'] and len(sp_x)>1:\n",
    "#         print(x, '|', ' '.join(sp_x[1:]))\n",
    "        return ' '.join(sp_x[1:])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T12:18:51.600251Z",
     "start_time": "2020-04-18T12:18:51.552089Z"
    }
   },
   "outputs": [],
   "source": [
    "train['selected_text'] = train['selected_text'].apply(lambda x: clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼接\n",
    "train = pd.concat([train, pseudo], ignore_index=True, sort=False)\n",
    "train.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T10:48:01.123268Z",
     "start_time": "2020-04-18T10:48:00.500535Z"
    }
   },
   "outputs": [],
   "source": [
    "train['start_pos'] = train.apply(lambda x: x['text'].find(x['selected_text']), axis=1)\n",
    "train['end_pos'] = train.apply(lambda x: x['start_pos']+len(x['selected_text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T10:48:01.980845Z",
     "start_time": "2020-04-18T10:48:01.978163Z"
    }
   },
   "outputs": [],
   "source": [
    "def contains(a, b):\n",
    "    for i in range(0, len(a)-len(b)+1):\n",
    "        flag = True\n",
    "        for j in range(0, len(b)):\n",
    "            if a[i+j]!=b[j]:\n",
    "                flag = False\n",
    "                break\n",
    "        if flag:\n",
    "            return True, i\n",
    "    return False, -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T10:48:15.689084Z",
     "start_time": "2020-04-18T10:48:02.684126Z"
    }
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "improve_count = 0\n",
    "for text, sp, ep, st in zip(train['text'].tolist(), train['start_pos'].tolist(), train['end_pos'].tolist(),\n",
    "                           train['selected_text'].tolist()):\n",
    "    split_text = text.split()\n",
    "    tokens, labels, invert_map, first_token, in_st = [], [], [], [], []\n",
    "    st_tokens = tokenizer.tokenize(' '+st)\n",
    "    cur_length = 0\n",
    "    \n",
    "    # token in selected_tokens\n",
    "    temp = np.zeros(len(text))\n",
    "    temp[sp:ep]=1\n",
    "    for idx, w in enumerate(split_text):\n",
    "        if sum(temp[cur_length+idx:cur_length+idx+len(w)])>0:\n",
    "            started = True# space\n",
    "        else:\n",
    "            started = False\n",
    "        for idx2, token in enumerate(tokenizer.tokenize(' '+w)):\n",
    "            first_token.append(True if idx2==0 else False)\n",
    "            tokens.append(token)\n",
    "            invert_map.append(idx)\n",
    "            if started:\n",
    "                labels.append(len(tokens)-1)\n",
    "                if token in st_tokens:\n",
    "                    in_st.append(1)\n",
    "                else:\n",
    "                    in_st.append(0)\n",
    "            else:\n",
    "                in_st.append(-100)\n",
    "        cur_length+=len(w)\n",
    "    start_token_idx = min(labels)\n",
    "    end_token_idx = max(labels)\n",
    "    start_token_idx, end_token_idx = _improve_answer_span(tokens, start_token_idx, end_token_idx,\n",
    "                                                         tokenizer, ' '+st)\n",
    "    \n",
    "#     token_contain, token_sp = contains(tokens, st_tokens)\n",
    "#     if token_contain:\n",
    "#         start_token_idx = token_sp\n",
    "#         end_token_idx = token_sp+len(st_tokens)-1\n",
    "    \n",
    "    start_word_idx = invert_map[start_token_idx]\n",
    "    end_word_idx = invert_map[end_token_idx]+1\n",
    "    assert ' '.join(split_text[start_word_idx:end_word_idx]).lower().find(st.lower())>=0\n",
    "    \n",
    "    data.append((tokens, start_token_idx, end_token_idx, invert_map, first_token, in_st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T10:48:15.760033Z",
     "start_time": "2020-04-18T10:48:15.690212Z"
    }
   },
   "outputs": [],
   "source": [
    "tokens, start, end, invert_map, first_token, in_st = zip(*data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T10:48:15.763452Z",
     "start_time": "2020-04-18T10:48:15.760944Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26610"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T10:48:15.782964Z",
     "start_time": "2020-04-18T10:48:15.764436Z"
    }
   },
   "outputs": [],
   "source": [
    "train['tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T10:48:15.819964Z",
     "start_time": "2020-04-18T10:48:15.784505Z"
    }
   },
   "outputs": [],
   "source": [
    "train['start'] = start\n",
    "train['end'] = end\n",
    "train['invert_map'] = invert_map\n",
    "train['first_token'] = first_token\n",
    "train['in_st'] = in_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T10:48:15.828355Z",
     "start_time": "2020-04-18T10:48:15.820995Z"
    }
   },
   "outputs": [],
   "source": [
    "senti2label = {\n",
    "    'positive':2,\n",
    "    'negative':0,\n",
    "    'neutral':1\n",
    "}\n",
    "train['senti_label']=train['sentiment'].apply(lambda x: senti2label[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T10:48:15.834049Z",
     "start_time": "2020-04-18T10:48:15.832276Z"
    }
   },
   "outputs": [],
   "source": [
    "train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T10:48:15.845581Z",
     "start_time": "2020-04-18T10:48:15.835146Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>type</th>\n",
       "      <th>start_pos</th>\n",
       "      <th>end_pos</th>\n",
       "      <th>tokens</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>invert_map</th>\n",
       "      <th>first_token</th>\n",
       "      <th>in_st</th>\n",
       "      <th>senti_label</th>\n",
       "      <th>pred</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>[Ġi, `, d, Ġhave, Ġresponded, ,, Ġif, Ġi, Ġwer...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>[0, 0, 0, 1, 2, 2, 3, 4, 5, 6]</td>\n",
       "      <td>[True, False, False, True, True, False, True, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "      <td>sooo sad</td>\n",
       "      <td>negative</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>[Ġso, oo, Ġsad, Ġi, Ġwill, Ġmiss, Ġyou, Ġhere,...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 9]</td>\n",
       "      <td>[True, False, True, True, True, True, True, Tr...</td>\n",
       "      <td>[1, 1, 1, -100, -100, -100, -100, -100, -100, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>normal</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>[Ġwhat, Ġinterview, !, Ġleave, Ġme, Ġalone]</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>[0, 1, 1, 2, 3, 4]</td>\n",
       "      <td>[True, True, False, True, True, True]</td>\n",
       "      <td>[-100, -100, -100, 1, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>sons of ****, why couldn`t they put them on th...</td>\n",
       "      <td>sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>[Ġsons, Ġof, Ġ****, ,, Ġwhy, Ġcouldn, `, t, Ġt...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1, 2, 2, 3, 4, 4, 4, 5, 6, 7, 8, 9, 10, 11...</td>\n",
       "      <td>[True, True, True, False, True, True, False, F...</td>\n",
       "      <td>[1, 1, 1, 1, -100, -100, -100, -100, -100, -10...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28b57f3990</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>[Ġhttp, ://, www, ., d, othe, b, oun, cy, ., c...</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[True, False, False, False, False, False, Fals...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                i`d have responded, if i were going   \n",
       "1  549e992a42      sooo sad i will miss you here in san diego!!!   \n",
       "2  9642c003ef                     what interview! leave me alone   \n",
       "3  358bd9e861  sons of ****, why couldn`t they put them on th...   \n",
       "4  28b57f3990  http://www.dothebouncy.com/smf - some shameles...   \n",
       "\n",
       "                                       selected_text sentiment    type  \\\n",
       "0                i`d have responded, if i were going   neutral  normal   \n",
       "1                                           sooo sad  negative  normal   \n",
       "2                                     leave me alone  negative  normal   \n",
       "3                                      sons of ****,  negative  normal   \n",
       "4  http://www.dothebouncy.com/smf - some shameles...   neutral  normal   \n",
       "\n",
       "   start_pos  end_pos                                             tokens  \\\n",
       "0          0       35  [Ġi, `, d, Ġhave, Ġresponded, ,, Ġif, Ġi, Ġwer...   \n",
       "1          0        8  [Ġso, oo, Ġsad, Ġi, Ġwill, Ġmiss, Ġyou, Ġhere,...   \n",
       "2         16       30        [Ġwhat, Ġinterview, !, Ġleave, Ġme, Ġalone]   \n",
       "3          0       13  [Ġsons, Ġof, Ġ****, ,, Ġwhy, Ġcouldn, `, t, Ġt...   \n",
       "4          0       92  [Ġhttp, ://, www, ., d, othe, b, oun, cy, ., c...   \n",
       "\n",
       "   start  end                                         invert_map  \\\n",
       "0      0    9                     [0, 0, 0, 1, 2, 2, 3, 4, 5, 6]   \n",
       "1      0    2            [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 9]   \n",
       "2      3    5                                 [0, 1, 1, 2, 3, 4]   \n",
       "3      0    3  [0, 1, 2, 2, 3, 4, 4, 4, 5, 6, 7, 8, 9, 10, 11...   \n",
       "4      0   26  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "\n",
       "                                         first_token  \\\n",
       "0  [True, False, False, True, True, False, True, ...   \n",
       "1  [True, False, True, True, True, True, True, Tr...   \n",
       "2              [True, True, False, True, True, True]   \n",
       "3  [True, True, True, False, True, True, False, F...   \n",
       "4  [True, False, False, False, False, False, Fals...   \n",
       "\n",
       "                                               in_st  senti_label pred  score  \n",
       "0                     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]            1  NaN    NaN  \n",
       "1  [1, 1, 1, -100, -100, -100, -100, -100, -100, ...            0  NaN    NaN  \n",
       "2                        [-100, -100, -100, 1, 1, 1]            0  NaN    NaN  \n",
       "3  [1, 1, 1, 1, -100, -100, -100, -100, -100, -10...            0  NaN    NaN  \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...            1  NaN    NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T10:48:15.853875Z",
     "start_time": "2020-04-18T10:48:15.846470Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26610, 16)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T10:48:15.856300Z",
     "start_time": "2020-04-18T10:48:15.854777Z"
    }
   },
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1991)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T10:48:15.883851Z",
     "start_time": "2020-04-18T10:48:15.856937Z"
    }
   },
   "outputs": [],
   "source": [
    "train['fold'] = 0\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(train, train['senti_label'])):\n",
    "    train.loc[valid_idx, 'fold'] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T10:48:15.888305Z",
     "start_time": "2020-04-18T10:48:15.884778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5323\n",
       "3    5322\n",
       "2    5322\n",
       "1    5322\n",
       "4    5321\n",
       "Name: fold, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['fold'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T10:48:15.974531Z",
     "start_time": "2020-04-18T10:48:15.889107Z"
    }
   },
   "outputs": [],
   "source": [
    "train.to_pickle('../input/train_roberta_with_pseudo.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal    24000\n",
       "pseudo     2610\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal    4791\n",
       "pseudo     531\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['fold']==1]['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
