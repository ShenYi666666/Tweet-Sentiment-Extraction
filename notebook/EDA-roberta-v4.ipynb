{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T11:58:51.278883Z",
     "start_time": "2020-04-12T11:58:49.024562Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import RobertaTokenizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T12:39:44.964828Z",
     "start_time": "2020-04-12T12:39:44.961636Z"
    }
   },
   "outputs": [],
   "source": [
    "def _improve_answer_span(doc_tokens, input_start, input_end, tokenizer, orig_answer_text):\n",
    "    \"\"\"Returns tokenized answer spans that better match the annotated answer.\"\"\"\n",
    "    tok_answer_text = ' '.join(sum([tokenizer.tokenize(w) for w in orig_answer_text.split()],[]))\n",
    "    \n",
    "    for new_start in range(input_start, input_end + 1):\n",
    "        for new_end in range(input_end, new_start - 1, -1):\n",
    "            text_span = \" \".join(doc_tokens[new_start : (new_end + 1)])\n",
    "            if text_span == tok_answer_text:\n",
    "                return (input_start, new_end)\n",
    "\n",
    "    return (input_start, input_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T11:58:51.966341Z",
     "start_time": "2020-04-12T11:58:51.924884Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/tweet-sentiment-extraction/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T11:58:52.255004Z",
     "start_time": "2020-04-12T11:58:52.171007Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('../../bert_models/roberta_large/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T11:58:52.410377Z",
     "start_time": "2020-04-12T11:58:52.392932Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27481, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T11:58:52.861363Z",
     "start_time": "2020-04-12T11:58:52.837396Z"
    }
   },
   "outputs": [],
   "source": [
    "train.dropna(subset=['text','selected_text'], how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T11:58:53.087618Z",
     "start_time": "2020-04-12T11:58:53.078694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27480, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T11:58:53.343685Z",
     "start_time": "2020-04-12T11:58:53.322247Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T11:58:53.629424Z",
     "start_time": "2020-04-12T11:58:53.560854Z"
    }
   },
   "outputs": [],
   "source": [
    "train['text'] = train['text'].apply(lambda x: ' '.join(x.strip().split()))\n",
    "train['selected_text'] = train['selected_text'].apply(lambda x: ' '.join(x.strip().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T11:58:54.615895Z",
     "start_time": "2020-04-12T11:58:53.962191Z"
    }
   },
   "outputs": [],
   "source": [
    "train['start_pos'] = train.apply(lambda x: x['text'].find(x['selected_text']), axis=1)\n",
    "train['end_pos'] = train.apply(lambda x: x['start_pos']+len(x['selected_text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T11:58:54.622511Z",
     "start_time": "2020-04-12T11:58:54.616970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    27480.000000\n",
       "mean        15.510153\n",
       "std         26.048759\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%         23.000000\n",
       "max        133.000000\n",
       "Name: start_pos, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['start_pos'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T12:40:00.987278Z",
     "start_time": "2020-04-12T12:39:47.245501Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "improve_count = 0\n",
    "for text, sp, ep, st in zip(train['text'].tolist(), train['start_pos'].tolist(), train['end_pos'].tolist(),\n",
    "                           train['selected_text'].tolist()):\n",
    "    split_text = text.split()\n",
    "    tokens, labels, invert_map, first_token = [], [], [], []\n",
    "    cur_length = 0\n",
    "    temp = np.zeros(len(text))\n",
    "    temp[sp:ep]=1\n",
    "    for idx, w in enumerate(split_text):\n",
    "        if sum(temp[cur_length+idx:cur_length+idx+len(w)])>0:\n",
    "            started = True# space\n",
    "        else:\n",
    "            started = False\n",
    "        for idx2, token in enumerate(tokenizer.tokenize(w)):\n",
    "            tokens.append(token)\n",
    "            if idx2==0:\n",
    "                first_token.append(True)\n",
    "            else:\n",
    "                first_token.append(False)\n",
    "            invert_map.append(idx)\n",
    "            if started:\n",
    "                labels.append(len(tokens)-1)\n",
    "        cur_length+=len(w)\n",
    "    start_token_idx = min(labels)\n",
    "    end_token_idx = max(labels)\n",
    "    start_word_idx = invert_map[start_token_idx]\n",
    "    end_word_idx = invert_map[end_token_idx]+1\n",
    "    assert ' '.join(split_text[start_word_idx:end_word_idx]).find(st)>=0\n",
    "    if ' '.join(split_text[start_word_idx:end_word_idx])!=st:\n",
    "        flag=True\n",
    "#         print(' '.join(split_text[start_word_idx:end_word_idx]),'|',st)\n",
    "    else:\n",
    "        flag=False\n",
    "    start_token_idx1, end_token_idx2 = _improve_answer_span(tokens, start_token_idx, end_token_idx,\n",
    "                                                         tokenizer, st)\n",
    "    if start_token_idx1!=start_token_idx or end_token_idx2!=end_token_idx:\n",
    "        improve_count+=1\n",
    "    data.append((tokens, start_token_idx1, end_token_idx2, invert_map, tokens[min(labels)],tokens[max(labels)], flag, first_token))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T12:40:00.991059Z",
     "start_time": "2020-04-12T12:40:00.988483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "414"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "improve_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T12:40:01.000504Z",
     "start_time": "2020-04-12T12:40:00.992297Z"
    }
   },
   "outputs": [],
   "source": [
    "tokens, start, end, invert_map, _, _, not_match, first_token = zip(*data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T12:40:01.003670Z",
     "start_time": "2020-04-12T12:40:01.001719Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27480"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T12:40:01.031198Z",
     "start_time": "2020-04-12T12:40:01.005141Z"
    }
   },
   "outputs": [],
   "source": [
    "train['tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T12:40:01.060300Z",
     "start_time": "2020-04-12T12:40:01.032487Z"
    }
   },
   "outputs": [],
   "source": [
    "train['start'] = start\n",
    "train['end'] = end\n",
    "train['invert_map'] = invert_map\n",
    "train['not_match']=not_match\n",
    "train['first_token'] = first_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T12:40:01.068470Z",
     "start_time": "2020-04-12T12:40:01.061167Z"
    }
   },
   "outputs": [],
   "source": [
    "senti2label = {\n",
    "    'positive':2,\n",
    "    'negative':0,\n",
    "    'neutral':1\n",
    "}\n",
    "train['senti_label']=train['sentiment'].apply(lambda x: senti2label[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T12:40:01.072427Z",
     "start_time": "2020-04-12T12:40:01.069554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10673216885007278"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['not_match'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T12:40:01.074793Z",
     "start_time": "2020-04-12T12:40:01.073118Z"
    }
   },
   "outputs": [],
   "source": [
    "train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T12:40:01.076786Z",
     "start_time": "2020-04-12T12:40:01.075475Z"
    }
   },
   "outputs": [],
   "source": [
    "# train['sentiment'] = train['sentiment'].apply(lambda x: tokenizer.tokenize(' '+x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T12:40:01.087393Z",
     "start_time": "2020-04-12T12:40:01.077430Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>start_pos</th>\n",
       "      <th>end_pos</th>\n",
       "      <th>tokens</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>invert_map</th>\n",
       "      <th>not_match</th>\n",
       "      <th>first_token</th>\n",
       "      <th>senti_label</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>[I, `, d, have, respond, ed, ,, if, I, were, g...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>[0, 0, 0, 1, 2, 2, 2, 3, 4, 5, 6]</td>\n",
       "      <td>False</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>[S, ooo, S, AD, I, will, miss, you, here, in, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 9]</td>\n",
       "      <td>False</td>\n",
       "      <td>[True, False, True, False, True, True, True, T...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>[my, boss, is, bull, ying, me, ...]</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>[0, 1, 2, 3, 3, 4, 4]</td>\n",
       "      <td>True</td>\n",
       "      <td>[True, True, True, True, False, True, False]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>[what, inter, view, !, leave, me, alone]</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>[0, 1, 1, 1, 2, 3, 4]</td>\n",
       "      <td>False</td>\n",
       "      <td>[True, True, False, False, True, True, True]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on th...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>[S, ons, of, ****, ,, why, could, n, `, t, the...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 0, 1, 2, 2, 3, 4, 4, 4, 4, 5, 6, 7, 8, 9, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[True, False, True, True, False, True, True, F...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861  Sons of ****, why couldn`t they put them on th...   \n",
       "\n",
       "                         selected_text sentiment  start_pos  end_pos  \\\n",
       "0  I`d have responded, if I were going   neutral          0       35   \n",
       "1                             Sooo SAD  negative          0        8   \n",
       "2                          bullying me  negative         11       22   \n",
       "3                       leave me alone  negative         16       30   \n",
       "4                        Sons of ****,  negative          0       13   \n",
       "\n",
       "                                              tokens  start  end  \\\n",
       "0  [I, `, d, have, respond, ed, ,, if, I, were, g...      0   10   \n",
       "1  [S, ooo, S, AD, I, will, miss, you, here, in, ...      0    3   \n",
       "2                [my, boss, is, bull, ying, me, ...]      3    5   \n",
       "3           [what, inter, view, !, leave, me, alone]      4    6   \n",
       "4  [S, ons, of, ****, ,, why, could, n, `, t, the...      0    4   \n",
       "\n",
       "                                          invert_map  not_match  \\\n",
       "0                  [0, 0, 0, 1, 2, 2, 2, 3, 4, 5, 6]      False   \n",
       "1         [0, 0, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 9]      False   \n",
       "2                              [0, 1, 2, 3, 3, 4, 4]       True   \n",
       "3                              [0, 1, 1, 1, 2, 3, 4]      False   \n",
       "4  [0, 0, 1, 2, 2, 3, 4, 4, 4, 4, 5, 6, 7, 8, 9, ...      False   \n",
       "\n",
       "                                         first_token  senti_label  fold  \n",
       "0  [True, False, False, True, True, False, False,...            1     0  \n",
       "1  [True, False, True, False, True, True, True, T...            0     0  \n",
       "2       [True, True, True, True, False, True, False]            0     0  \n",
       "3       [True, True, False, False, True, True, True]            0     0  \n",
       "4  [True, False, True, True, False, True, True, F...            0     0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T12:40:01.090114Z",
     "start_time": "2020-04-12T12:40:01.088399Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T12:40:01.092518Z",
     "start_time": "2020-04-12T12:40:01.091008Z"
    }
   },
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T12:40:01.106847Z",
     "start_time": "2020-04-12T12:40:01.093361Z"
    }
   },
   "outputs": [],
   "source": [
    "train['fold'] = 0\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(train, train['senti_label'])):\n",
    "    train.loc[valid_idx, 'fold'] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T12:40:01.110807Z",
     "start_time": "2020-04-12T12:40:01.107645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5498\n",
       "1    5497\n",
       "4    5495\n",
       "3    5495\n",
       "2    5495\n",
       "Name: fold, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['fold'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T12:40:01.192721Z",
     "start_time": "2020-04-12T12:40:01.111531Z"
    }
   },
   "outputs": [],
   "source": [
    "train.to_pickle('../input/train_roberta_v4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
